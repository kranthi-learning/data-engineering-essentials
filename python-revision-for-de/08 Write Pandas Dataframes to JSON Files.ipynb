{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_names(schemas,ds_name,sorting_key='column_position'):\n",
    "    column_details = schemas[ds_name]\n",
    "    columns = sorted(column_details,key= lambda col: col[sorting_key])\n",
    "    return [col['column_name'] for col in columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemas=json.load(open('C:/Users/Suchi/Projects/data/retail_db/schemas.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_columns = get_column_names(schemas,'orders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['order_id', 'order_date', 'order_customer_id', 'order_status']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.read_csv(\n",
    "        'C:/Users/Suchi/Projects/data/retail_db/orders/part-00000',\n",
    "names=order_columns\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('c:/Users/Suchi/Projects/data/retail_db/orders_json', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0morders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0morient\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Literal['split', 'records', 'index', 'table', 'columns', 'values'] | None\"\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdate_format\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdouble_precision\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'int'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mforce_ascii\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool_t'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdate_unit\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'TimeUnit'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ms'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdefault_handler\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Callable[[Any], JSONSerializable] | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool_t'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcompression\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'CompressionOptions'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool_t | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mindent\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'int | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mstorage_options\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'StorageOptions | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Literal['a', 'w']\"\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'str | None'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Convert the object to a JSON string.\n",
      "\n",
      "Note NaN's and None will be converted to null and datetime objects\n",
      "will be converted to UNIX timestamps.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "path_or_buf : str, path object, file-like object, or None, default None\n",
      "    String, path object (implementing os.PathLike[str]), or file-like\n",
      "    object implementing a write() function. If None, the result is\n",
      "    returned as a string.\n",
      "orient : str\n",
      "    Indication of expected JSON string format.\n",
      "\n",
      "    * Series:\n",
      "\n",
      "        - default is 'index'\n",
      "        - allowed values are: {'split', 'records', 'index', 'table'}.\n",
      "\n",
      "    * DataFrame:\n",
      "\n",
      "        - default is 'columns'\n",
      "        - allowed values are: {'split', 'records', 'index', 'columns',\n",
      "          'values', 'table'}.\n",
      "\n",
      "    * The format of the JSON string:\n",
      "\n",
      "        - 'split' : dict like {'index' -> [index], 'columns' -> [columns],\n",
      "          'data' -> [values]}\n",
      "        - 'records' : list like [{column -> value}, ... , {column -> value}]\n",
      "        - 'index' : dict like {index -> {column -> value}}\n",
      "        - 'columns' : dict like {column -> {index -> value}}\n",
      "        - 'values' : just the values array\n",
      "        - 'table' : dict like {'schema': {schema}, 'data': {data}}\n",
      "\n",
      "        Describing the data, where data component is like ``orient='records'``.\n",
      "\n",
      "date_format : {None, 'epoch', 'iso'}\n",
      "    Type of date conversion. 'epoch' = epoch milliseconds,\n",
      "    'iso' = ISO8601. The default depends on the `orient`. For\n",
      "    ``orient='table'``, the default is 'iso'. For all other orients,\n",
      "    the default is 'epoch'.\n",
      "double_precision : int, default 10\n",
      "    The number of decimal places to use when encoding\n",
      "    floating point values. The possible maximal value is 15.\n",
      "    Passing double_precision greater than 15 will raise a ValueError.\n",
      "force_ascii : bool, default True\n",
      "    Force encoded string to be ASCII.\n",
      "date_unit : str, default 'ms' (milliseconds)\n",
      "    The time unit to encode to, governs timestamp and ISO8601\n",
      "    precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      "    microsecond, and nanosecond respectively.\n",
      "default_handler : callable, default None\n",
      "    Handler to call if object cannot otherwise be converted to a\n",
      "    suitable format for JSON. Should receive a single argument which is\n",
      "    the object to convert and return a serialisable object.\n",
      "lines : bool, default False\n",
      "    If 'orient' is 'records' write out line-delimited json format. Will\n",
      "    throw ValueError if incorrect 'orient' since others are not\n",
      "    list-like.\n",
      "compression : str or dict, default 'infer'\n",
      "    For on-the-fly compression of the output data. If 'infer' and 'path_or_buf' is\n",
      "    path-like, then detect compression from the following extensions: '.gz',\n",
      "    '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "    (otherwise no compression).\n",
      "    Set to ``None`` for no compression.\n",
      "    Can also be a dict with key ``'method'`` set\n",
      "    to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      "    other key-value pairs are forwarded to\n",
      "    ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "    ``bz2.BZ2File``, ``zstandard.ZstdCompressor``, ``lzma.LZMAFile`` or\n",
      "    ``tarfile.TarFile``, respectively.\n",
      "    As an example, the following could be passed for faster compression and to create\n",
      "    a reproducible gzip archive:\n",
      "    ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      "\n",
      "    .. versionadded:: 1.5.0\n",
      "        Added support for `.tar` files.\n",
      "\n",
      "    .. versionchanged:: 1.4.0 Zstandard support.\n",
      "\n",
      "index : bool or None, default None\n",
      "    The index is only used when 'orient' is 'split', 'index', 'column',\n",
      "    or 'table'. Of these, 'index' and 'column' do not support\n",
      "    `index=False`.\n",
      "\n",
      "indent : int, optional\n",
      "   Length of whitespace used to indent each record.\n",
      "\n",
      "storage_options : dict, optional\n",
      "    Extra options that make sense for a particular storage connection, e.g.\n",
      "    host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "    are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "    URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "    forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "    details, and for more examples on storage options refer `here\n",
      "    <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "    highlight=storage_options#reading-writing-remote-files>`_.\n",
      "\n",
      "mode : str, default 'w' (writing)\n",
      "    Specify the IO mode for output when supplying a path_or_buf.\n",
      "    Accepted args are 'w' (writing) and 'a' (append) only.\n",
      "    mode='a' is only supported when lines is True and orient is 'records'.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "None or str\n",
      "    If path_or_buf is None, returns the resulting json format as a\n",
      "    string. Otherwise returns None.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "read_json : Convert a JSON string to pandas object.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The behavior of ``indent=0`` varies from the stdlib, which does not\n",
      "indent the output but does insert newlines. Currently, ``indent=0``\n",
      "and the default ``indent=None`` are equivalent in pandas, though this\n",
      "may change in a future release.\n",
      "\n",
      "``orient='table'`` contains a 'pandas_version' field under 'schema'.\n",
      "This stores the version of `pandas` used in the latest revision of the\n",
      "schema.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from json import loads, dumps\n",
      ">>> df = pd.DataFrame(\n",
      "...     [[\"a\", \"b\"], [\"c\", \"d\"]],\n",
      "...     index=[\"row 1\", \"row 2\"],\n",
      "...     columns=[\"col 1\", \"col 2\"],\n",
      "... )\n",
      "\n",
      ">>> result = df.to_json(orient=\"split\")\n",
      ">>> parsed = loads(result)\n",
      ">>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "{\n",
      "    \"columns\": [\n",
      "        \"col 1\",\n",
      "        \"col 2\"\n",
      "    ],\n",
      "    \"index\": [\n",
      "        \"row 1\",\n",
      "        \"row 2\"\n",
      "    ],\n",
      "    \"data\": [\n",
      "        [\n",
      "            \"a\",\n",
      "            \"b\"\n",
      "        ],\n",
      "        [\n",
      "            \"c\",\n",
      "            \"d\"\n",
      "        ]\n",
      "    ]\n",
      "}\n",
      "\n",
      "Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      "Note that index labels are not preserved with this encoding.\n",
      "\n",
      ">>> result = df.to_json(orient=\"records\")\n",
      ">>> parsed = loads(result)\n",
      ">>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "[\n",
      "    {\n",
      "        \"col 1\": \"a\",\n",
      "        \"col 2\": \"b\"\n",
      "    },\n",
      "    {\n",
      "        \"col 1\": \"c\",\n",
      "        \"col 2\": \"d\"\n",
      "    }\n",
      "]\n",
      "\n",
      "Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      "\n",
      ">>> result = df.to_json(orient=\"index\")\n",
      ">>> parsed = loads(result)\n",
      ">>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "{\n",
      "    \"row 1\": {\n",
      "        \"col 1\": \"a\",\n",
      "        \"col 2\": \"b\"\n",
      "    },\n",
      "    \"row 2\": {\n",
      "        \"col 1\": \"c\",\n",
      "        \"col 2\": \"d\"\n",
      "    }\n",
      "}\n",
      "\n",
      "Encoding/decoding a Dataframe using ``'columns'`` formatted JSON:\n",
      "\n",
      ">>> result = df.to_json(orient=\"columns\")\n",
      ">>> parsed = loads(result)\n",
      ">>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "{\n",
      "    \"col 1\": {\n",
      "        \"row 1\": \"a\",\n",
      "        \"row 2\": \"c\"\n",
      "    },\n",
      "    \"col 2\": {\n",
      "        \"row 1\": \"b\",\n",
      "        \"row 2\": \"d\"\n",
      "    }\n",
      "}\n",
      "\n",
      "Encoding/decoding a Dataframe using ``'values'`` formatted JSON:\n",
      "\n",
      ">>> result = df.to_json(orient=\"values\")\n",
      ">>> parsed = loads(result)\n",
      ">>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "[\n",
      "    [\n",
      "        \"a\",\n",
      "        \"b\"\n",
      "    ],\n",
      "    [\n",
      "        \"c\",\n",
      "        \"d\"\n",
      "    ]\n",
      "]\n",
      "\n",
      "Encoding with Table Schema:\n",
      "\n",
      ">>> result = df.to_json(orient=\"table\")\n",
      ">>> parsed = loads(result)\n",
      ">>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "{\n",
      "    \"schema\": {\n",
      "        \"fields\": [\n",
      "            {\n",
      "                \"name\": \"index\",\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"col 1\",\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"col 2\",\n",
      "                \"type\": \"string\"\n",
      "            }\n",
      "        ],\n",
      "        \"primaryKey\": [\n",
      "            \"index\"\n",
      "        ],\n",
      "        \"pandas_version\": \"1.4.0\"\n",
      "    },\n",
      "    \"data\": [\n",
      "        {\n",
      "            \"index\": \"row 1\",\n",
      "            \"col 1\": \"a\",\n",
      "            \"col 2\": \"b\"\n",
      "        },\n",
      "        {\n",
      "            \"index\": \"row 2\",\n",
      "            \"col 1\": \"c\",\n",
      "            \"col 2\": \"d\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\suchi\\projects\\python-revision-for-de\\pr-venv\\lib\\site-packages\\pandas\\core\\generic.py\n",
      "\u001b[1;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "orders.to_json?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.to_json('c:/Users/Suchi/Projects/data/retail_db/orders_json/part-00000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.to_json(\n",
    "        'c:/Users/Suchi/Projects/data/retail_db/orders_json/part-00000',\n",
    "        orient='records',\n",
    "        lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>order_customer_id</th>\n",
       "      <th>order_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-07-25 00:00:00.0</td>\n",
       "      <td>11599</td>\n",
       "      <td>CLOSED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-07-25 00:00:00.0</td>\n",
       "      <td>256</td>\n",
       "      <td>PENDING_PAYMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-07-25 00:00:00.0</td>\n",
       "      <td>12111</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-07-25 00:00:00.0</td>\n",
       "      <td>8827</td>\n",
       "      <td>CLOSED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2013-07-25 00:00:00.0</td>\n",
       "      <td>11318</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68878</th>\n",
       "      <td>68879</td>\n",
       "      <td>2014-07-09 00:00:00.0</td>\n",
       "      <td>778</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68879</th>\n",
       "      <td>68880</td>\n",
       "      <td>2014-07-13 00:00:00.0</td>\n",
       "      <td>1117</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68880</th>\n",
       "      <td>68881</td>\n",
       "      <td>2014-07-19 00:00:00.0</td>\n",
       "      <td>2518</td>\n",
       "      <td>PENDING_PAYMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68881</th>\n",
       "      <td>68882</td>\n",
       "      <td>2014-07-22 00:00:00.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>ON_HOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68882</th>\n",
       "      <td>68883</td>\n",
       "      <td>2014-07-23 00:00:00.0</td>\n",
       "      <td>5533</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68883 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       order_id             order_date  order_customer_id     order_status\n",
       "0             1  2013-07-25 00:00:00.0              11599           CLOSED\n",
       "1             2  2013-07-25 00:00:00.0                256  PENDING_PAYMENT\n",
       "2             3  2013-07-25 00:00:00.0              12111         COMPLETE\n",
       "3             4  2013-07-25 00:00:00.0               8827           CLOSED\n",
       "4             5  2013-07-25 00:00:00.0              11318         COMPLETE\n",
       "...         ...                    ...                ...              ...\n",
       "68878     68879  2014-07-09 00:00:00.0                778         COMPLETE\n",
       "68879     68880  2014-07-13 00:00:00.0               1117         COMPLETE\n",
       "68880     68881  2014-07-19 00:00:00.0               2518  PENDING_PAYMENT\n",
       "68881     68882  2014-07-22 00:00:00.0              10000          ON_HOLD\n",
       "68882     68883  2014-07-23 00:00:00.0               5533         COMPLETE\n",
       "\n",
       "[68883 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json(\n",
    "        'c:/Users/Suchi/Projects/data/retail_db/orders_json/part-00000',\n",
    "        lines=True   \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pr-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
